{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.utils import resample\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, zero_one_loss\n",
    "from scipy.stats import mode\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lectura y normalización de data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "dataset = pd.read_csv('./data/Cardiotocographic-Training.csv')\n",
    "#dataset = pd.read_csv(\"dataset.csv\")\n",
    "\n",
    "y = dataset.CLASE.to_numpy()\n",
    "X = dataset.drop('CLASE', axis=1).to_numpy()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap(X, y, model, k, c, g):\n",
    "    indices = np.array([i for i in range (len(X))])\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1s = []\n",
    "    errors = []\n",
    "    for i in range(k):\n",
    "        train_index = resample(indices, n_samples=k, replace=True)\n",
    "        test_index = np.array([j for j in indices if j not in train_index])\n",
    "        \n",
    "        x_train, y_train = X[train_index], y[train_index]\n",
    "        x_test, y_test = X[test_index], y[test_index]\n",
    "        \n",
    "        model.fit(x_train, y_train)\n",
    "        y_pred = model.predict(x_test)\n",
    "\n",
    "        errors.append(zero_one_loss(y_test, y_pred))\n",
    "\n",
    "        precision = precision_score(y_test, y_pred, average='micro') # micro porque toma en cuenta el desbalanceaminto de clases\n",
    "        precisions.append(precision)\n",
    "\n",
    "        recall = recall_score(y_test, y_pred, average='micro')\n",
    "        recalls.append(recall)\n",
    "\n",
    "        f1 = f1_score(y_test, y_pred, average='micro')\n",
    "        f1s.append(f1)\n",
    "\n",
    "    return [np.mean(errors), np.var(errors), c, g, precisions, recalls, f1s, errors]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold(X, y, model, k, c, g):\n",
    "    skf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1s = []\n",
    "    errors = []\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        x_train, y_train = X[train_index], y[train_index]\n",
    "        x_test, y_test = X[test_index], y[test_index]\n",
    "\n",
    "        model.fit(x_train, y_train)\n",
    "        y_pred = model.predict(x_test)\n",
    "\n",
    "        errors.append(zero_one_loss(y_test, y_pred))\n",
    "\n",
    "        precision = precision_score(y_test, y_pred, average='micro') # micro porque toma en cuenta el desbalanceaminto de clases\n",
    "        precisions.append(precision)\n",
    "\n",
    "        recall = recall_score(y_test, y_pred, average='micro')\n",
    "        recalls.append(recall)\n",
    "\n",
    "        f1 = f1_score(y_test, y_pred, average='micro')\n",
    "        f1s.append(f1)\n",
    "\n",
    "    return [np.mean(errors), np.var(errors), c, g, precisions, recalls, f1s, errors]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(x1, x2):\n",
    "    distance = np.sqrt(np.sum((x1-x2)**2))\n",
    "    return distance\n",
    "\n",
    "\n",
    "class KNN:\n",
    "    def __init__(self, k):\n",
    "        self.k = k\n",
    "\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = [self._predict(x) for x in X]\n",
    "        return predictions\n",
    "    \n",
    "\n",
    "    def _predict(self, x):\n",
    "\n",
    "        distances = [distance(x, x_train) for x_train in self.X_train]\n",
    "\n",
    "\n",
    "        indices = np.argsort(distances)[:self.k]\n",
    "        labels = [self.y_train[i] for i in indices]\n",
    "\n",
    "        most_common = mode(labels)\n",
    "\n",
    "        return most_common.mode[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuneo el modelo con Bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neighbors:  3 \n",
      "Bias:  0.23091808771179112 \n",
      "Varianza 0.0015909344425265946\n",
      "Neighbors:  5 \n",
      "Bias:  0.224195171026157 \n",
      "Varianza 5.050676291147304e-05\n",
      "Neighbors:  7 \n",
      "Bias:  0.2219315895372233 \n",
      "Varianza 2.429061289264594e-07\n",
      "Neighbors:  9 \n",
      "Bias:  0.22198189134808857 \n",
      "Varianza 1.5434660275534964e-07\n",
      "Neighbors:  11 \n",
      "Bias:  0.22157947686116702 \n",
      "Varianza 2.6567857851332167e-07\n"
     ]
    }
   ],
   "source": [
    "neighbors = [3, 5, 7, 9, 11]\n",
    "g = []\n",
    "\n",
    "results_knn_bootstrap = []\n",
    "\n",
    "for k in neighbors:\n",
    "    results_knn_bootstrap.append(bootstrap(X, y, KNN(k), 10, k, g))\n",
    "\n",
    "for r in results_knn_bootstrap:\n",
    "    print(\"Neighbors: \", r[2], \"\\nBias: \", r[0], \"\\nVarianza\", r[1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valores de métricas del mejor modelo KNN con Bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.7780181086519116\n",
      "Recall   :  0.7780181086519116\n",
      "F1       :  0.7780181086519115\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision: \", np.mean(results_knn_bootstrap[3][4]))\n",
    "print(\"Recall   : \", np.mean(results_knn_bootstrap[3][5]))\n",
    "print(\"F1       : \", np.mean(results_knn_bootstrap[3][6]))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuneo el modelo con K-Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neighbors:  3 \n",
      "Bias:  0.08210552763819094 \n",
      "Varianza 0.00048635221332794527\n",
      "Neighbors:  5 \n",
      "Bias:  0.09110804020100502 \n",
      "Varianza 0.000653632162066615\n",
      "Neighbors:  7 \n",
      "Bias:  0.10112060301507535 \n",
      "Varianza 0.0003838426049847234\n",
      "Neighbors:  9 \n",
      "Bias:  0.10161306532663314 \n",
      "Varianza 0.0003031034317315224\n",
      "Neighbors:  11 \n",
      "Bias:  0.10211557788944722 \n",
      "Varianza 0.00034986449837125396\n"
     ]
    }
   ],
   "source": [
    "neighbors = [3, 5, 7, 9, 11]\n",
    "g = []\n",
    "\n",
    "results_knn_kfold = []\n",
    "\n",
    "for k in neighbors:\n",
    "    results_knn_kfold.append(k_fold(X, y, KNN(k), 10, k, g))\n",
    "\n",
    "for r in results_knn_kfold:\n",
    "    print(\"Neighbors: \", r[2], \"\\nBias: \", r[0], \"\\nVarianza\", r[1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valores de métricas del mejor modelo KNN con K-Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.8983869346733669\n",
      "Recall   :  0.8983869346733669\n",
      "F1       :  0.8983869346733669\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision: \", np.mean(results_knn_kfold[3][4]))\n",
    "print(\"Recall   : \", np.mean(results_knn_kfold[3][5]))\n",
    "print(\"F1       : \", np.mean(results_knn_kfold[3][6]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
